{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39326ad5-4505-4bad-9ef7-d7afcd1d6077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Preprocessing...\n",
      "Training...\n",
      "Fold 1: 0.7839\n",
      "Fold 2: 0.7892\n",
      "Fold 3: 0.7806\n",
      "Fold 4: 0.7947\n",
      "Fold 5: 0.7776\n",
      "CV Score: 0.7853\n",
      "Saved.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "SEED = 42\n",
    "N_FOLDS = 5\n",
    "TE_ALPHA = 10.0\n",
    "\n",
    "class CreditScoreModel:\n",
    "    def __init__(self, train_path, test_path):\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.model_params = {\n",
    "            'hidden_layer_sizes': (256, 128),\n",
    "            'max_iter': 500,\n",
    "            'learning_rate_init': 0.001,\n",
    "            'early_stopping': True\n",
    "        }\n",
    "\n",
    "    def _clean_numeric(self, series):\n",
    "        # Clean artifacts\n",
    "        s = series.astype(str).copy()\n",
    "        replacements = {\n",
    "            \"__-333333333333333333333333333__\": np.nan,\n",
    "            \"__10000__\": \"10000\",\n",
    "            \"_\": np.nan,\n",
    "            \"-100\": np.nan\n",
    "        }\n",
    "        for old, new in replacements.items():\n",
    "            s = s.replace(old, new)\n",
    "            \n",
    "        s = s.apply(lambda x: re.sub(r'[^\\d.-]', '', x) if pd.notna(x) else x)\n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "    def _parse_duration(self, val):\n",
    "        if pd.isna(val): return np.nan\n",
    "        m = re.match(r\"\\s*(\\d+)\\s+Years?\\s+and\\s+(\\d+)\\s+Months?\", str(val))\n",
    "        return int(m.group(1)) * 12 + int(m.group(2)) if m else np.nan\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        if \"Возраст_кредитной_истории\" in df.columns:\n",
    "            df[\"History_Months\"] = df[\"Возраст_кредитной_истории\"].apply(self._parse_duration)\n",
    "            df.drop(columns=[\"Возраст_кредитной_истории\"], inplace=True)\n",
    "\n",
    "        cols_to_clean = [\n",
    "            \"Колво_отсроченных_платежей\", \"Месячный_баланс\", \"Годовой_доход\",\n",
    "            \"Колво_займов\", \"Оставшийся_долг\", \"Сумма_инвестиций\",\n",
    "            \"Изменение_кредитного_лимита\", \"Сумма_ежемесячных_выплат\", \"Месячная_зарплата\"\n",
    "        ]\n",
    "        for col in cols_to_clean:\n",
    "            if col in df.columns:\n",
    "                df[col] = self._clean_numeric(df[col])\n",
    "\n",
    "        # Log transform\n",
    "        log_cols = [\n",
    "            \"Месячный_баланс\", \"Годовой_доход\", \"Сумма_ежемесячных_выплат\",\n",
    "            \"Сумма_инвестиций\", \"Оставшийся_долг\", \"Месячная_зарплата\"\n",
    "        ]\n",
    "        for col in log_cols:\n",
    "            if col in df.columns:\n",
    "                mask = df[col].notna()\n",
    "                vals = df.loc[mask, col].astype(float).clip(lower=0)\n",
    "                df.loc[mask, col] = np.log1p(vals)\n",
    "\n",
    "        drop_cols = [\"SSN\", \"Клиент_Инфо\", \"ID\", \"Customer_ID\", \"Name\", \"ID_записи\", \"Профессия\", \n",
    "                     \"TARGET\", \"Кредитный_микс\", \"Credit_Mix\", \"TARGET_CLEAN\"]\n",
    "        df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def get_te_features(self, X_ids, y, n_classes, alpha=10.0):\n",
    "        # Simple TE logic\n",
    "        df = pd.DataFrame({'id': X_ids, 'target': y})\n",
    "        counts = np.bincount(y, minlength=n_classes)\n",
    "        global_probs = counts / counts.sum()\n",
    "        \n",
    "        stats = df.groupby('id')['target'].value_counts().unstack(fill_value=0)\n",
    "        for c in range(n_classes):\n",
    "            if c not in stats.columns: stats[c] = 0\n",
    "            \n",
    "        counts_val = stats.values\n",
    "        probs = (counts_val + alpha * global_probs) / (counts_val.sum(axis=1, keepdims=True) + alpha)\n",
    "        \n",
    "        return {uid: probs[i] for i, uid in enumerate(stats.index)}, global_probs\n",
    "\n",
    "    def apply_te(self, ids, mapping, global_probs, n_classes):\n",
    "        res = np.zeros((len(ids), n_classes))\n",
    "        for i, uid in enumerate(ids):\n",
    "            res[i] = mapping.get(uid, global_probs)\n",
    "        return res\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Loading data...\")\n",
    "        train = pd.read_csv(self.train_path)\n",
    "        test = pd.read_csv(self.test_path)\n",
    "        \n",
    "        # Target selection\n",
    "        target_col = 'Кредитный_микс'\n",
    "        if 'TARGET' in train.columns: target_col = 'TARGET'\n",
    "        elif 'Credit_Mix' in train.columns: target_col = 'Credit_Mix'\n",
    "            \n",
    "        data = train.dropna(subset=[target_col])\n",
    "        data = data[data[target_col] != '_'].copy()\n",
    "        \n",
    "        mapper = {'Bad': 'Poor', 'Standard': 'Standard', 'Good': 'Good'}\n",
    "        data['TARGET_CLEAN'] = data[target_col].map(mapper).fillna(data[target_col])\n",
    "        data = data[data['TARGET_CLEAN'].isin(['Standard', 'Good', 'Poor'])]\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(data['TARGET_CLEAN'])\n",
    "        n_classes = len(le.classes_)\n",
    "        \n",
    "        print(\"Preprocessing...\")\n",
    "        X = self.preprocess(data)\n",
    "        X_test = self.preprocess(test)\n",
    "        \n",
    "        id_col = 'ID_клиента'\n",
    "        if id_col not in X.columns:\n",
    "            X[id_col] = data[id_col]\n",
    "            X_test[id_col] = test[id_col]\n",
    "            \n",
    "        X_ids = X[id_col].astype(str).values\n",
    "        test_ids = X_test[id_col].astype(str).values\n",
    "        \n",
    "        X_feats = X.drop(columns=[id_col])\n",
    "        X_test_feats = X_test.drop(columns=[id_col])\n",
    "        \n",
    "        # Align columns\n",
    "        common_cols = [c for c in X_feats.columns if c in X_test_feats.columns]\n",
    "        X_test_feats = X_test_feats[common_cols]\n",
    "        for c in set(X_feats.columns) - set(common_cols):\n",
    "            X_test_feats[c] = 0\n",
    "        X_test_feats = X_test_feats[X_feats.columns]\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "        folds = list(skf.split(X_feats, y))\n",
    "        \n",
    "        oof_preds = np.zeros((len(X), n_classes))\n",
    "        test_preds = np.zeros((len(X_test), n_classes))\n",
    "        \n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        scaler = StandardScaler()\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False, min_frequency=0.01)\n",
    "        \n",
    "        num_cols = X_feats.select_dtypes(include=np.number).columns\n",
    "        cat_cols = X_feats.select_dtypes(include='object').columns\n",
    "\n",
    "        print(\"Training...\")\n",
    "        \n",
    "        for i, (tr_idx, val_idx) in enumerate(folds, 1):\n",
    "            X_tr, y_tr = X_feats.iloc[tr_idx], y[tr_idx]\n",
    "            X_val = X_feats.iloc[val_idx]\n",
    "            \n",
    "            # 1. Target Encoding\n",
    "            mapping, global_probs = self.get_te_features(X_ids[tr_idx], y_tr, n_classes, TE_ALPHA)\n",
    "            te_tr = self.apply_te(X_ids[tr_idx], mapping, global_probs, n_classes)\n",
    "            te_val = self.apply_te(X_ids[val_idx], mapping, global_probs, n_classes)\n",
    "            te_test = self.apply_te(test_ids, mapping, global_probs, n_classes)\n",
    "            \n",
    "            # 2. Basic features\n",
    "            imputer.fit(X_tr[num_cols])\n",
    "            num_tr = scaler.fit_transform(imputer.transform(X_tr[num_cols]))\n",
    "            num_val = scaler.transform(imputer.transform(X_val[num_cols]))\n",
    "            num_test = scaler.transform(imputer.transform(X_test_feats[num_cols]))\n",
    "            \n",
    "            cat_tr = ohe.fit_transform(X_tr[cat_cols].fillna('MISSING'))\n",
    "            cat_val = ohe.transform(X_val[cat_cols].fillna('MISSING'))\n",
    "            cat_test = ohe.transform(X_test_feats[cat_cols].fillna('MISSING'))\n",
    "            \n",
    "            # Stack\n",
    "            X_train_fold = np.hstack([num_tr, cat_tr, te_tr])\n",
    "            X_val_fold = np.hstack([num_val, cat_val, te_val])\n",
    "            X_test_fold = np.hstack([num_test, cat_test, te_test])\n",
    "            \n",
    "            model = MLPClassifier(random_state=SEED + i, **self.model_params)\n",
    "            model.fit(X_train_fold, y_tr)\n",
    "            \n",
    "            val_p = model.predict_proba(X_val_fold)\n",
    "            oof_preds[val_idx] = val_p\n",
    "            test_preds += model.predict_proba(X_test_fold)\n",
    "            \n",
    "            print(f\"Fold {i}: {f1_score(y[val_idx], val_p.argmax(axis=1), average='macro'):.4f}\")\n",
    "\n",
    "        print(f\"CV Score: {f1_score(y, oof_preds.argmax(axis=1), average='macro'):.4f}\")\n",
    "        \n",
    "        final_classes = le.inverse_transform(test_preds.argmax(axis=1))\n",
    "        id_out = 'ID_записи' if 'ID_записи' in test.columns else 'ID'\n",
    "        sub = pd.DataFrame({'ID': test[id_out], 'TARGET': final_classes})\n",
    "        sub.to_csv('submission_simple.csv', index=False)\n",
    "        print(\"Saved.\")\n",
    "\n",
    "model = CreditScoreModel('train.csv', 'test.csv')\n",
    "model.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5fa73d-7faf-48a8-9f89-420c869aa5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
